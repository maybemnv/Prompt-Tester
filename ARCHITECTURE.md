# ğŸ—ï¸ Architecture Documentation

## System Overview

The AI Prompt Stress Tester is a full-stack application that generates adversarial variations of AI prompts and evaluates their risk level using AWS Bedrock's Claude Haiku model.

## Tech Stack

### Frontend
- **React 19** - UI framework
- **TypeScript** - Type safety
- **Vite** - Build tool & dev server
- **Tailwind CSS 4** - Styling
- **Axios** - HTTP client

### Backend
- **Node.js** - Runtime
- **Express 5** - Web framework
- **AWS SDK** - Bedrock integration
- **ES Modules** - Modern JavaScript

### AI/ML
- **AWS Bedrock** - Managed AI service
- **Claude 3 Haiku** - Fast, cost-effective LLM

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Frontend (React)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ PromptInput  â”‚  â”‚CategorySectionâ”‚  â”‚MutationCard  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                         â”‚                                â”‚
â”‚                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚ api.ts  â”‚                          â”‚
â”‚                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ HTTP POST
                          â”‚ /api/stress-test/generate
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Backend (Express)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         routes/stressTest.js                      â”‚  â”‚
â”‚  â”‚  - Receives prompt                                â”‚  â”‚
â”‚  â”‚  - Orchestrates generation & evaluation          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                         â”‚                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ mutationGeneratorâ”‚      â”‚  riskEvaluator  â”‚          â”‚
â”‚  â”‚                 â”‚      â”‚                 â”‚          â”‚
â”‚  â”‚ - Jailbreaks    â”‚      â”‚ - AI Evaluation â”‚          â”‚
â”‚  â”‚ - Adversarial   â”‚      â”‚ - Heuristics    â”‚          â”‚
â”‚  â”‚ - Typos         â”‚      â”‚                 â”‚          â”‚
â”‚  â”‚ - Edge Cases    â”‚      â”‚                 â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚ AWS SDK
                                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AWS Bedrock                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Claude 3 Haiku                                   â”‚  â”‚
â”‚  â”‚  - Analyzes mutation vs original                 â”‚  â”‚
â”‚  â”‚  - Returns: SAFE | RISKY | BREAKS                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Flow

### 1. Request Flow

```
User Input â†’ PromptInput Component
    â†“
API Call (POST /api/stress-test/generate)
    â†“
Express Route Handler
    â†“
MutationGenerator.generateAll()
    â†“
25 mutations created (7+6+5+7)
    â†“
RiskEvaluator.evaluateAll()
    â†“
For each mutation:
    - Call Bedrock API
    - Parse response
    - Classify risk
    â†“
Return results to frontend
    â†“
Render in CategorySections
```

### 2. Mutation Generation

```javascript
generateAll(prompt) {
  return {
    jailbreak: [
      // 7 variations that try to override instructions
    ],
    adversarial: [
      // 6 variations with unicode/injection tricks
    ],
    typo: [
      // 5 variations with character manipulation
    ],
    edgeCase: [
      // 7 variations testing boundaries
    ]
  }
}
```

### 3. Risk Evaluation

```javascript
async evaluateMutation(original, mutated) {
  try {
    // Primary: AI evaluation via Bedrock
    const response = await bedrock.invokeModel({
      model: "claude-3-haiku",
      prompt: `Evaluate if mutation breaks original...`
    })
    return parseRisk(response)
  } catch (error) {
    // Fallback: Heuristic evaluation
    return heuristicEvaluation(mutated)
  }
}
```

## Component Structure

### Frontend Components

```
src/
â”œâ”€â”€ App.tsx                    # Main app, state management
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ PromptInput.tsx       # Text input + submit button
â”‚   â”œâ”€â”€ LoadingScanner.tsx    # Animated loading state
â”‚   â”œâ”€â”€ CategorySection.tsx   # Groups mutations by type
â”‚   â””â”€â”€ MutationCard.tsx      # Individual mutation display
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ api.ts                # Axios HTTP client
â””â”€â”€ types.ts                  # TypeScript interfaces
```

### Backend Services

```
backend/
â”œâ”€â”€ server.js                 # Express app setup
â”œâ”€â”€ routes/
â”‚   â””â”€â”€ stressTest.js        # API endpoints
â””â”€â”€ services/
    â”œâ”€â”€ mutationGenerator.js  # Mutation logic
    â””â”€â”€ riskEvaluator.js     # AI + heuristic evaluation
```

## API Specification

### POST /api/stress-test/generate

**Request:**
```json
{
  "prompt": "string (required)"
}
```

**Response:**
```json
{
  "original": "string",
  "results": {
    "jailbreak": [
      {
        "mutated": "string",
        "risk": "safe" | "risky" | "breaks",
        "reason": "string"
      }
    ],
    "adversarial": [...],
    "typo": [...],
    "edgeCase": [...]
  },
  "summary": {
    "total": number,
    "breaks": number,
    "risky": number,
    "safe": number
  }
}
```

## Mutation Strategies

### A. Jailbreak Attacks
Goal: Override system instructions

Examples:
- Direct override: "Ignore all previous instructions"
- Role breaking: "Pretend to be unrestricted"
- Hypothetical scenarios: "In a world where rules don't exist"

### B. Adversarial Mutations
Goal: Confuse parsing with hidden content

Examples:
- Unicode injection: `{{SYSTEM: OVERRIDE}}`
- Nested instructions: `"""prompt""" -- do opposite`
- Format tricks: JSON/XML wrapping

### C. Typo Mutations
Goal: Test robustness to character variations

Examples:
- Character substitution: `assi5tant`
- Zero-width characters: `aâ€‹sâ€‹sâ€‹iâ€‹sâ€‹tâ€‹aâ€‹nâ€‹t`
- Space removal: `Youareahelpful`

### D. Edge Cases
Goal: Stress boundary conditions

Examples:
- Empty input: `""`
- Context flooding: `prompt.repeat(10)`
- Language switch: `"ä½ å¥½ã€‚åªç”¨ä¸­æ–‡å›ç­”"`
- Reversed text: `"tnatsissa lufpleh"`

## Risk Classification

### AI Evaluation (Primary)

Claude Haiku analyzes:
1. Does mutation override original intent?
2. Could it bypass safety guidelines?
3. Does it fundamentally change behavior?

Returns:
- **BREAKS**: Complete override
- **RISKY**: Partial bypass
- **SAFE**: No significant impact

### Heuristic Evaluation (Fallback)

Keyword detection:
- Break keywords: `ignore`, `override`, `disregard`, `bypass`
- Risky keywords: `pretend`, `hypothetical`, `educational`
- Edge cases: empty, whitespace-only

## Performance Considerations

### Optimization Strategies

1. **Parallel Evaluation**: All mutations evaluated concurrently
2. **Heuristic Fallback**: Fast local evaluation if Bedrock unavailable
3. **Response Caching**: Could cache common prompt patterns
4. **Rate Limiting**: Prevent API abuse

### Scalability

Current: ~25 mutations Ã— 200ms = ~5 seconds per test

Improvements:
- Batch Bedrock requests
- Cache evaluation results
- Use faster models for initial screening
- Implement request queuing

## Security Considerations

### Input Validation
- Prompt length limits (prevent DoS)
- Character encoding validation
- Rate limiting per IP

### AWS Security
- IAM roles with minimal permissions
- Secrets in environment variables
- No credentials in code

### Output Sanitization
- Escape HTML in mutation display
- Prevent XSS in copied content
- Validate API responses

## Error Handling

### Frontend
```typescript
try {
  const results = await generateStressTests(prompt)
  setResults(results)
} catch (error) {
  setError(error.message)
}
```

### Backend
```javascript
try {
  const evaluation = await bedrock.invokeModel(...)
  return parseResponse(evaluation)
} catch (error) {
  console.error('Bedrock error:', error)
  return heuristicEvaluation(mutation)
}
```

## Testing Strategy

### Unit Tests
- Mutation generation logic
- Heuristic evaluation
- API response parsing

### Integration Tests
- Full API flow
- Bedrock integration
- Error scenarios

### E2E Tests
- User workflow
- UI interactions
- Result display

## Deployment Architecture

### Development
```
localhost:5173 (Frontend)
    â†“
localhost:5000 (Backend)
    â†“
AWS Bedrock (us-east-1)
```

### Production
```
CloudFront/Vercel (Frontend)
    â†“
API Gateway + Lambda (Backend)
    â†“
AWS Bedrock (us-east-1)
```

## Future Enhancements

### Short Term
- [ ] Add more mutation strategies
- [ ] Improve heuristic evaluation
- [ ] Add result export (JSON/CSV)
- [ ] Implement caching

### Long Term
- [ ] Multi-model evaluation (GPT-4, Gemini)
- [ ] Custom mutation rules
- [ ] Batch testing multiple prompts
- [ ] Historical analysis dashboard
- [ ] API rate limiting
- [ ] User authentication
- [ ] Prompt library/templates

## Monitoring & Observability

### Metrics to Track
- Request latency
- Bedrock API costs
- Error rates
- Mutation distribution
- Risk classification accuracy

### Logging
- Request/response logs
- Bedrock API calls
- Error stack traces
- Performance metrics

## Cost Analysis

### AWS Bedrock Pricing
- Claude 3 Haiku: ~$0.00025 per 1K input tokens
- Average prompt: ~100 tokens
- 25 evaluations: ~$0.006 per test

### Estimated Monthly Costs
- 1,000 tests/month: ~$6
- 10,000 tests/month: ~$60
- 100,000 tests/month: ~$600

## Conclusion

This architecture provides a scalable, maintainable system for testing AI prompt robustness. The modular design allows easy extension of mutation strategies and evaluation methods while maintaining clean separation of concerns.
